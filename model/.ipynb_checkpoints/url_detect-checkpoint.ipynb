{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e64b75cd",
   "metadata": {},
   "source": [
    "Author: J Tarness \n",
    "Date: 2022-07-17\n",
    "Sources:\n",
    "- Data+feature eng: https://www.kaggle.com/code/hamzamanssor/detection-malicious-url-using-ml-models/notebook\n",
    "-model creation: https://towardsdatascience.com/a-journey-through-xgboost-milestone-2-f3410109be5a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49361e22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: xgboost in /home/j/.local/lib/python3.10/site-packages (1.6.1)\n",
      "Requirement already satisfied: numpy in /home/j/.local/lib/python3.10/site-packages (from xgboost) (1.22.0)\n",
      "Requirement already satisfied: scipy in /home/j/.local/lib/python3.10/site-packages (from xgboost) (1.7.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: sklearn in /home/j/.local/lib/python3.10/site-packages (0.0)\n",
      "Requirement already satisfied: scikit-learn in /home/j/.local/lib/python3.10/site-packages (from sklearn) (1.0.2)\n",
      "Requirement already satisfied: numpy>=1.14.6 in /home/j/.local/lib/python3.10/site-packages (from scikit-learn->sklearn) (1.22.0)\n",
      "Requirement already satisfied: scipy>=1.1.0 in /home/j/.local/lib/python3.10/site-packages (from scikit-learn->sklearn) (1.7.3)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/j/.local/lib/python3.10/site-packages (from scikit-learn->sklearn) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/j/.local/lib/python3.10/site-packages (from scikit-learn->sklearn) (3.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas in /home/j/.local/lib/python3.10/site-packages (1.3.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /home/j/.local/lib/python3.10/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /home/j/.local/lib/python3.10/site-packages (from pandas) (2021.3)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /home/j/.local/lib/python3.10/site-packages (from pandas) (1.22.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3.10/site-packages (from python-dateutil>=2.7.3->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: numpy in /home/j/.local/lib/python3.10/site-packages (1.22.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: plotly in /home/j/.local/lib/python3.10/site-packages (5.6.0)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /home/j/.local/lib/python3.10/site-packages (from plotly) (8.0.1)\n",
      "Requirement already satisfied: six in /usr/lib/python3.10/site-packages (from plotly) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: matplotlib in /home/j/.local/lib/python3.10/site-packages (3.5.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/j/.local/lib/python3.10/site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/j/.local/lib/python3.10/site-packages (from matplotlib) (4.28.5)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/j/.local/lib/python3.10/site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/j/.local/lib/python3.10/site-packages (from matplotlib) (1.22.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/lib/python3.10/site-packages (from matplotlib) (21.3)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/lib/python3.10/site-packages (from matplotlib) (9.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /usr/lib/python3.10/site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/j/.local/lib/python3.10/site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: seaborn in /home/j/.local/lib/python3.10/site-packages (0.11.2)\n",
      "Requirement already satisfied: numpy>=1.15 in /home/j/.local/lib/python3.10/site-packages (from seaborn) (1.22.0)\n",
      "Requirement already satisfied: scipy>=1.0 in /home/j/.local/lib/python3.10/site-packages (from seaborn) (1.7.3)\n",
      "Requirement already satisfied: pandas>=0.23 in /home/j/.local/lib/python3.10/site-packages (from seaborn) (1.3.5)\n",
      "Requirement already satisfied: matplotlib>=2.2 in /home/j/.local/lib/python3.10/site-packages (from seaborn) (3.5.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/j/.local/lib/python3.10/site-packages (from matplotlib>=2.2->seaborn) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/j/.local/lib/python3.10/site-packages (from matplotlib>=2.2->seaborn) (4.28.5)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/j/.local/lib/python3.10/site-packages (from matplotlib>=2.2->seaborn) (1.3.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/lib/python3.10/site-packages (from matplotlib>=2.2->seaborn) (21.3)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/lib/python3.10/site-packages (from matplotlib>=2.2->seaborn) (9.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /usr/lib/python3.10/site-packages (from matplotlib>=2.2->seaborn) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/j/.local/lib/python3.10/site-packages (from matplotlib>=2.2->seaborn) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /home/j/.local/lib/python3.10/site-packages (from pandas>=0.23->seaborn) (2021.3)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib>=2.2->seaborn) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: tld in /home/j/.local/lib/python3.10/site-packages (0.12.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement re (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for re\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement urllib (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for urllib\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#install libraries\n",
    "%pip install xgboost\n",
    "%pip install sklearn\n",
    "%pip install pandas\n",
    "%pip install numpy\n",
    "%pip install plotly\n",
    "%pip install matplotlib\n",
    "%pip install seaborn\n",
    "%pip install tld\n",
    "%pip install re\n",
    "%pip install urllib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "04cd2d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libs\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from urllib.parse import urlparse\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from tld import get_tld, is_tld\n",
    "from colorama import Fore\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "19f84c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load dataset\n",
    "data = pd.read_csv('malicious_phish.csv')\n",
    "data.head()\n",
    "data['url'] = data['url'].replace('www.', '', regex=True)\n",
    "rem = {\"Category\": {\"benign\": 0, \"defacement\": 1, \"phishing\":2, \"malware\":3}}\n",
    "data['Category'] = data['type']\n",
    "data = data.replace(rem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ca7a0646",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "url         0\n",
       "type        0\n",
       "Category    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6bdfddf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature extraction\n",
    "data['url_len'] = data['url'].apply(lambda x: len(str(x)))\n",
    "def process_tld(url):\n",
    "    try:\n",
    "        res = get_tld(url, as_object = True, fail_silently=False,fix_protocol=True)\n",
    "        pri_domain= res.parsed_url.netloc\n",
    "    except :\n",
    "        pri_domain= None\n",
    "    return pri_domain\n",
    "data['domain'] = data['url'].apply(lambda i: process_tld(i))\n",
    "feature = ['@','?','-','=','.','#','%','+','$','!','*',',','//']\n",
    "for a in feature:\n",
    "    data[a] = data['url'].apply(lambda i: i.count(a))\n",
    "def abnormal_url(url):\n",
    "    hostname = urlparse(url).hostname\n",
    "    hostname = str(hostname)\n",
    "    match = re.search(hostname, url)\n",
    "    if match:\n",
    "        # print match.group()\n",
    "        return 1\n",
    "    else:\n",
    "        # print 'No matching pattern found'\n",
    "        return 0\n",
    "data['abnormal_url'] = data['url'].apply(lambda i: abnormal_url(i))\n",
    "def httpSecure(url):\n",
    "    htp = urlparse(url).scheme\n",
    "    match = str(htp)\n",
    "    if match=='https':\n",
    "        # print match.group()\n",
    "        return 1\n",
    "    else:\n",
    "        # print 'No matching pattern found'\n",
    "        return 0\n",
    "data['https'] = data['url'].apply(lambda i: httpSecure(i))\n",
    "def digit_count(url):\n",
    "    digits = 0\n",
    "    for i in url:\n",
    "        if i.isnumeric():\n",
    "            digits = digits + 1\n",
    "    return digits\n",
    "data['digits']= data['url'].apply(lambda i: digit_count(i))\n",
    "def letter_count(url):\n",
    "    letters = 0\n",
    "    for i in url:\n",
    "        if i.isalpha():\n",
    "            letters = letters + 1\n",
    "    return letters\n",
    "data['letters']= data['url'].apply(lambda i: letter_count(i))\n",
    "def Shortining_Service(url):\n",
    "    match = re.search('bit\\.ly|goo\\.gl|shorte\\.st|go2l\\.ink|x\\.co|ow\\.ly|t\\.co|tinyurl|tr\\.im|is\\.gd|cli\\.gs|'\n",
    "                      'yfrog\\.com|migre\\.me|ff\\.im|tiny\\.cc|url4\\.eu|twit\\.ac|su\\.pr|twurl\\.nl|snipurl\\.com|'\n",
    "                      'short\\.to|BudURL\\.com|ping\\.fm|post\\.ly|Just\\.as|bkite\\.com|snipr\\.com|fic\\.kr|loopt\\.us|'\n",
    "                      'doiop\\.com|short\\.ie|kl\\.am|wp\\.me|rubyurl\\.com|om\\.ly|to\\.ly|bit\\.do|t\\.co|lnkd\\.in|'\n",
    "                      'db\\.tt|qr\\.ae|adf\\.ly|goo\\.gl|bitly\\.com|cur\\.lv|tinyurl\\.com|ow\\.ly|bit\\.ly|ity\\.im|'\n",
    "                      'q\\.gs|is\\.gd|po\\.st|bc\\.vc|twitthis\\.com|u\\.to|j\\.mp|buzurl\\.com|cutt\\.us|u\\.bb|yourls\\.org|'\n",
    "                      'x\\.co|prettylinkpro\\.com|scrnch\\.me|filoops\\.info|vzturl\\.com|qr\\.net|1url\\.com|tweez\\.me|v\\.gd|'\n",
    "                      'tr\\.im|link\\.zip\\.net',\n",
    "                      url)\n",
    "    if match:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "data['Shortining_Service'] = data['url'].apply(lambda x: Shortining_Service(x))\n",
    "def having_ip_address(url):\n",
    "    match = re.search(\n",
    "        '(([01]?\\\\d\\\\d?|2[0-4]\\\\d|25[0-5])\\\\.([01]?\\\\d\\\\d?|2[0-4]\\\\d|25[0-5])\\\\.([01]?\\\\d\\\\d?|2[0-4]\\\\d|25[0-5])\\\\.'\n",
    "        '([01]?\\\\d\\\\d?|2[0-4]\\\\d|25[0-5])\\\\/)|'  # IPv4\n",
    "        '(([01]?\\\\d\\\\d?|2[0-4]\\\\d|25[0-5])\\\\.([01]?\\\\d\\\\d?|2[0-4]\\\\d|25[0-5])\\\\.([01]?\\\\d\\\\d?|2[0-4]\\\\d|25[0-5])\\\\.'\n",
    "        '([01]?\\\\d\\\\d?|2[0-4]\\\\d|25[0-5])\\\\/)|'  # IPv4 with port\n",
    "        '((0x[0-9a-fA-F]{1,2})\\\\.(0x[0-9a-fA-F]{1,2})\\\\.(0x[0-9a-fA-F]{1,2})\\\\.(0x[0-9a-fA-F]{1,2})\\\\/)' # IPv4 in hexadecimal\n",
    "        '(?:[a-fA-F0-9]{1,4}:){7}[a-fA-F0-9]{1,4}|'\n",
    "        '([0-9]+(?:\\.[0-9]+){3}:[0-9]+)|'\n",
    "        '((?:(?:\\d|[01]?\\d\\d|2[0-4]\\d|25[0-5])\\.){3}(?:25[0-5]|2[0-4]\\d|[01]?\\d\\d|\\d)(?:\\/\\d{1,2})?)', url)  # Ipv6\n",
    "    if match:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "data['having_ip_address'] = data['url'].apply(lambda i: having_ip_address(i))\n",
    "X = data.drop(['url','type','Category','domain'],axis=1)#,'type_code'\n",
    "y = data['Category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dd747ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0f954336",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_clf = xgb.XGBClassifier(max_depth=3, n_estimators=100,\n",
    "                            objective='multi:softprob',num_classes=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8ba4d7ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:25:59] WARNING: ../src/learner.cc:627: \n",
      "Parameters: { \"num_classes\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, gamma=0, gpu_id=-1, grow_policy='depthwise',\n",
       "              importance_type=None, interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,\n",
       "              max_delta_step=0, max_depth=3, max_leaves=0, min_child_weight=1,\n",
       "              missing=nan, monotone_constraints='()', n_estimators=100,\n",
       "              n_jobs=0, num_classes=4, num_parallel_tree=1,\n",
       "              objective='multi:softprob', predictor='auto', random_state=0, ...)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "40f3265b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = xgb_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0c545bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "ytrue = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d2f49295",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.866\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: \", np.round(accuracy_score(ytrue, y_pred), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ef37c374",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_clf.save_model(\"xgb_clf.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
